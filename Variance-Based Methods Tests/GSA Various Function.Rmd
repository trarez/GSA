---
title: "GSA on some functions: K-Function, Ishigami, Liu, Sobol' G, Morris"
output: html_notebook
editor_options: 
  markdown: 
    wrap: 72
---

## Introduction

```{r message=FALSE, warning=FALSE, include=FALSE}
library(ggplot2)
library(sensobol)
library(tidyverse)
library(data.table)

set.seed(10)

N <- 4096 <- 2^12 # number of samples
R <- 100 # number of bootstrap replicates
type <- "norm" # type of bootstrap
conf <- 0.95 # confidence level for bootstrapping
```

In this notebook, Variance-based GSA will be performed for different functions. 
These functions are used to benchmark SA tools, because they have analytical solutions for the variance-based sensitivity indices. These solutions will be the baseline comparison for the results obtained with numerical methods, such as the
ones in the `sensobol` package. 
All the sensitivity analyses will be performed with a fixed number of samples (N = 4096 = 2^12).

Most of the functions are retrieved from [**"A sensitivity analysis of the PAWN sensitivity index"**](https://www.sciencedirect.com/science/article/pii/S1364815219306607), by Puy A., Lo Piano S., Saltelli A. In this paper, these are used to test a Sensitivity Analysis method called PAWN.

## K-Function

From [**"Variance based sensitivity analysis of model output. Design and estimator for the total sensitivity index"**](https://www.sciencedirect.com/science/article/pii/S0010465509003087) by Saltelli et al. (2009). 

The K-Function is defined as:

$$ K = \sum_{i = 1}^k (-1)^i \prod^i_{j = i} X_j$$.

It is a function with strong interactions. 
Analytical results for Si and STi can be calculated analytically and thus compared. 
The actual results (with $k = 10$) available in the paper ["A function dataset for benchmarking in sensitivity analysis"](https://www.sciencedirect.com/science/article/pii/S2352340922002827) by I. Azzini and R. Rosati.

```{r include=FALSE}
# Load necessary library
library(ggplot2)
library(sensobol)
library(tidyverse)
```

Create the K function:
```{r}
calculate_K <- function(x, k) {
  #pre allocaiton
  K <- 0
  for (i in 1:k) {
    product <- prod(x[1:i])
    K <- K + ((-1)^i) * product
  }
  
  return(K)
}
```

```{r}
k = 10
N <- 2^12; R <- 100

type <- "norm"; conf <- 0.50
nameParams <- paste("X", 1:k, sep = "")

matt <- sobol_matrices(N = N, params = nameParams, type = "R")

# Initialize a numeric vector to store the results
results_k <- numeric(nrow(matt))

# Loop through each row and apply the bateman_equation function
for (x in 1:nrow(matt)) {
  results_k[x] <- calculate_K(x = as.numeric(matt[x, ]), k = k)
}

ind <- sobol_indices(Y = results_k, N = N, params = nameParams, boot = TRUE, R = R, type = type, conf = conf)

cols <- colnames(ind$results)[1:3]
ind$results[, `:=`((cols), round(.SD, 6)), .SDcols = (cols)]

# Plot the results with the ordered parameters
plot(ind)
```

```{r}
plot(ind)
```


```{r}
# Function to calculate T1(i, k)
T1 <- function(i, k) {
  term1 <- (1/2) * (1 - (1/3)^(i-2))
  term2 <- (1/3)^(k-i+1)
  return (term1 - term2)
}

# Function to calculate T2(i)
T2 <- function(i) {
  return ((1/2) * (1 - (1/3)^(i-1)))
}

# Function to calculate T3(i, k)
T3 <- function(i, k) {
  term1 <- (1/6) * (1/2)^k * (1 - (1/3)^(k+1))
  term2 <- (-1)^(i-1) * (1/3)^(i-1)
  return (term1 + term2)
}

# Function to calculate T4(i)
T4 <- function(i) {
  term1 <- (-1)^(i+1) * (1/3)^(i-3)
  term2 <- 4 * (1/3)^(i-1)
  return ((1/5) * (term1 - term2))
}

# Function to calculate T5(i, k)
T5 <- function(i, k) {
  term1 <- (-1)^(k+1) * (1/3)^(k-2)
  term2 <- (-1)^(k-i+1) * (1/3)^(i*(i-1))
  return ((1/5) * (term1 + term2))
}

# Function to calculate V(K)
V_K <- function(k) {
  term1 <- 1/10 * (1/3)^k
  term2 <- 1/18
  term3 <- -1/9 * (1/2)^k
  term4 <- (-1)^(k+1) * 2/45 * (1/3)^k
  return (term1 + term2 + term3 + term4)
}

# Function to calculate E(K^2)
E_K2 <- function(k) {
  term1 <- 1/6 * (1 - (1/3)^k)
  term2 <- 4/15 * (-1)^(k+1) * (1/2)^k
  term3 <- (1/3)^k
  return (term1 + term2 + term3)
}

# Function to calculate E_i
E_i <- function(i) {
  term1 <- 1/6 * (1 - (1/3)^(i-1))
  term2 <- 4/15 * (-1)^(i-1) * (1/2)^(i-1)
  term3 <- (1/3)^(i-1)
  return (term1 + term2 + term3)
}

# Function to calculate STi(K)
STi <- function(i, k) {
  V_K_value <- V_K(k)
  E_K2_value <- E_K2(k)
  E_i_value <- E_i(i)
  
  T1_value <- T1(i, k)
  T2_value <- T2(i)
  T3_value <- T3(i, k)
  T4_value <- T4(i)
  T5_value <- T5(i, k)
  
  numerator <- E_K2_value - E_i_value - 1/4 * (T1_value - 2 * T2_value + T3_value - T4_value - T5_value)
  denominator <- V_K_value
  
  result <- numerator / denominator
  
  
  return (result)
}

# Example usage
i <- 4
k <- 5
result <- STi(i, k)
print(result)
```

## Ishigami Function

First used in Ishigami and Homma in the paper ["*An importance quantification technique in uncertainty analysis for computer models*â€](https://ieeexplore.ieee.org/document/151285) (1990), it involves the sine trigonometric function.

$$ Y = \sin(X_1) + a \sin^2(X_2) + bX_3^4 \sin(X_1) \\ X_i \sim U[-\pi, \pi] \\ a = 7, b = 0.1$$
$a$ and $b$ are arbitrary values that govern the importance of the second and third term. The function is nonlinear and have strong interactions between the input variables. 


From [this page](https://uqworld.org/t/ishigami-function/55), first-order and total-order indices are defined:

These are retrieved, as we already know, from the variance decomposition formula:

$$\text{V}(Y) = \mathbb{E}_{X_i}\left(\text{V}_{X_{\sim i}}(Y | X_i)\right) + \text{V}_{X_i}\left(\mathbb{E}_{X_{\sim i}}(Y | X_i)\right)$$
To retrieve the analytical values of the sensitivity indices, we first calculate the variances:

Output variance:

- $\text{V}[Y] = \frac{a^2}{8} + \frac{b\pi^4}{5} + \frac{b^2\pi^8}{18} + \frac{1}{2}$
```{r}
a <- 2; b <- 1
totVar <- a^2/8 + b*pi^4/5 + b^2*pi^8/18 + 1/2
totVar
```
Input factors variance:

- $V_1 = 0.5\left(1 + \frac{b\pi^4}{5}\right)^2$
- $V_2 = 0$
- $V_3 = \frac{a^2}{8}$
```{r}
V1 <- 0.5*(1 + b*pi^4/5)^2
V2 <- 0
V3 <- a^2/8

cat("V1:", round(V1, 3), "| V2:", round(V2, 3), "| V3:", round(V3, 3), sep = " ")
```
The **first-order sensitivity indices** are:

- $S_i = \frac{V_i}{\text{V[Y]}}, \forall i$
```{r}
S1 <- V1/totVar
S2 <- V2/totVar
S3 <- V3/totVar

cat("S1:", round(S1, 3), "| S2:", round(S2, 3), "| S3:", round(S3, 3), sep = " ")
```
These are always $0 \leq S_i \leq 1$; they quantify the impact of individual input factors on the output variance of a model, without considering (first or higher order) interactions between variables.

Now we calculate the **total-order sensitivity indices**, by first computing the total variances:

- $V_{T_1} = 0.5\left(1 + \frac{b\pi^4}{5}\right)^2 + \frac{8b^2\pi^8}{225}$
- $V_{T_2} = \frac{a^2}{8}$
- $V_{T_3} = \frac{8b^2\pi^8}{225}$

Total SI:

- $S_{T_i} = \frac{V_{T_i}}{\text{V}[Y]}$
```{r}
VT1 <- 0.5 * (1 + (b*pi^4/5)^2)+8*b^2*pi^8/225
VT2 <- a^2/8
VT3 <- 8*b^2*pi^8/225

ST1 <- VT1/totVar
ST2 <- VT2/totVar
ST3 <- VT3/totVar

cat("ST1:", round(ST1, 3), "| ST2:", round(ST2, 3), "| ST3:", round(ST3, 3), sep = " ")
```
Total-order sensitivity indices, instead, quantify the overall contribution of an input variable to the output variance, including all its interactions with other variables of any order.

As $N \rightarrow \infty$, $S_{T_i} = \hat{S_{T_i}}, \forall i$. This is the convergence that must keep in mind in order to have correct and consistent sensitivity indices.

Before performing the sensitivity analysis, we generate the data and plot the output distribution of the Ishigami function as a basic tool for uncertainty analysis:

```{r}
# a <- 7; b <- 0.1
nameParams <- c("X1", "X2", "X3")
mat <- sobol_matrices(N = N, params = nameParams, type = "R")

# for (i in 1:3) {
#   mat[, i] <- runif(nrow(mat), -pi, pi)
# }
# 
# ishigami <- function(X, a, b) {
#   Y <- sin(X[, 1]) + a * sin(X[, 2])^2 + b * X[, 3]^4 * sin(X[, 1])
#   return(Y)
# }

Y <- ishigami_Fun(mat)

ggplot(data.frame(Y), aes(x = Y)) +
  geom_histogram(bins = 60, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(title = "Output Distribution of Ishigami Function (UA)",
       x = "Y",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10))
```
The distribution is strongly leptokurtic.

A sensitivity analysis is performed with the `sensobol::sobol_indices` function. It returns the sensitivity indices for the input variables. At its basic specification (i.e., minimum parameter specification), it returns the first-order and total-order indices. 
```{r}
ind <- sobol_indices(Y = Y, N = N, params = nameParams)
plot(ind) + 
  labs(title = "Sensitivity Analysis of Ishigami Function") + 
  theme(legend.position = "right")
```
An improved specification of the function allows to perform bootstrapping, which is a resampling technique that allows to estimate the uncertainty of the sensitivity indices, represented by a *lower* and  an *upper* bounds:

```{r}
ind <- sobol_indices(Y = Y, N = N, params = nameParams, boot = TRUE, R = R, type = type, conf = conf)
plot(ind) + 
  labs(title = "Sensitivity Analysis of Ishigami Function") + 
  theme(legend.position = "right")
```

With this plot, we can clearly appreciate the great presence of interactions, by watching the difference between first-order and total-order indices for each parameter. The high values of $S_{T_1}$ and $S_{T_2}$ indicate that the output variance is highly influenced by the interactions between the input variables.

Another efficient way to visualize the interactions is through scatterplots. These are obtained by plotting the output against each input factor. The scatterplots are useful to visually assess the degree of non-linearity:
```{r}
plot_scatter(data = mat, N = N, Y = Y, params = nameParams) + labs(title = "Scatterplots of Ishigami Function")
```
The red dots show the mean y value in each bin (the default number of bins is 30).


The same analysis will be reiterated for the other functions.

## Liu Function 
(from [Relative Entropy Based Method for Probabilistic Sensitivity Analysis in Engineering Design](https://asmedigitalcollection.asme.org/mechanicaldesign/article-abstract/128/2/326/471654/Relative-Entropy-Based-Method-for-Probabilistic?redirectedFrom=fulltext), 2006)

$$Y = X_1 / X_2 \\ X_1 \sim \chi^2(10) \\ X_2 \sim \chi^2(13.978)$$

```{r}
Liu_Funct <- function(dof1, dof2) {
  "Ratio of two Chi-squared distribution. 
  'dof1' defines the degrees of freedom of the first distribution, while 'dof2' the second one"
    X1 <- rchisq(N, dof1)
    X2 <- rchisq(N, dof2)
    y <- X1 / X2
  return(y)
}

Y <- Liu_Funct(10, 13.978)

ggplot(data.frame(Y), aes(x = Y)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(title = "Output Distribution of Liu Function (UA)",
       x = "Y",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10))
```

```{r}
nameParams <- c("X1", "X2")
mat <- sobol_matrices(N = N, params = nameParams, type = "R")
mat[, 1] <- rchisq(nrow(mat), 10)
mat[, 2] <- rchisq(nrow(mat), 13.978)

Y <- rep(NA, nrow(mat))

for (row in 1:nrow(mat)) {
  Y[row] <- rchisq(1, 10) / rchisq(1, 13.978)
}

# ind <- sobol_indices(Y = Y, N = N, params = nameParams, boot = TRUE, R = R, type = "type", conf = conf)
# ^^ error to understand

# Do not perform bootstrap on indices
ind <- sobol_indices(Y = Y, N = N, params = nameParams)

plot(ind)
```

Scatterplots:
```{r}
plot_scatter(data = mat, N = N, Y = Y, params = nameParams)+ labs(title = "Scatterplots of Liu Function")
```


## Sobol G Function

(From [On quasi-Monte Carlo integrations](https://www.sciencedirect.com/science/article/abs/pii/S0378475498000962), 1998)

$$ Y = \prod_{i = 1}^k \frac{|4X_i - 2| + a_i}{1 + a_i} \\ k = 8 \\ X_i \sim U[0, 1] \\ a = (0, 1, 4.5, 99, 99, 99, 99)$$
the $a_i$ values are arbitrary. The higher they are, the less sensible the output is to the specific input. The provided values come from Sobol (1998).

```{r}
a_vector <- c(0, 1, 4.5, 99, 99, 99, 99)

sobol_Funct <- function(matrix, vector) {
  y <- 1
  
  for (j in 1:length(vector)) {
    y <- y * (abs(4 * matrix[, j] - 2) + vector[j])/(1 + vector[j])
  }
  return(y)
}

k <- length(a_vector) #number of parameters
params <- paste("x", 1:k, sep = "")
mat <- sobol_matrices(params = params, N = N, type = "R")

Y <- sobol_Funct(mat, a_vector)

ggplot(data.frame(Y), aes(x = Y)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(title = "Output Distribution of Sobol G Function (UA)",
       x = "Y",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10))
```
Sensitivity Analysis:

```{r}
ind <- sobol_indices(Y = Y, N = N, params = params, boot = TRUE, R = R, type = type, conf = conf)

plot(ind) + labs(title = "Sensitivity Analysis of Sobol G Function")
```
Scatterplots:
```{r}
plot_scatter(data = mat, N = N, Y = Y, params = params) + labs(title = "Scatterplots of Sobol G Function")
```

## Morris Function

(From [Factorial Sampling Plans for Preliminary Computational Experiments](https://abe.ufl.edu/Faculty/jjones/ABE_5646/2010/Morris.1991%20SA%20paper.pdf), 1991)


This function may look daunting at first, but each summation represent an order effects and interactions. It follows the functional decomposition scheme:

$$f = f_0 + \sum_i f_i + \sum_i \sum_{j >i}f_{ij} + \ldots +f_{12\ldots k}$$

In details, it includes first-order effects, second-order interactions, third-order interactions, and fourth-order interactions, with varying coefficients for different groups of factors.


$$
Y = \beta_0 + \sum_{i=1}^{20} \beta_i w_i +  \sum_{i<j}^{20} \beta_{i,j} w_i w_j + \sum_{i<j<l}^{20} \beta_{i,j,l} w_i w_j w_l + \sum_{i<j<l<s}^{20} \beta_{i,j,l,s} w_i w_j w_l w_s
$$

$$
\text{where } w_i = 2(X_i - 0.5) \space \forall  i \text{ except for } i = 3, 5, 7, \text{ where } w_i = 2\left(\frac{1.1X_i}{X_i + 0.1} - 0.5\right), \\ \ X_i \sim \text{U}[0, 1]
$$

$$
\beta_i = 20, \ i = 1, 2, \ldots, 10 \\
\beta_{i,j} = -15, \ i = 1, 2, \ldots, 6 \\
\beta_{i,j,l} = -10, \ i = 1, 2, \ldots, 5 \\
\beta_{i,j,l,s} = 5, \ i = 1, 2, \ldots, 4

$$

```{r}
library(sensitivity)
library(ggplot2)

# Define the Morris function
morris_function <- function(X) {
  # Ensure X is a matrix or data frame with 20 columns
  if (ncol(X) != 20) stop("X must have 20 columns")
  
  # Calculate w
  w <- apply(X, 2, function(x) {
    ifelse(which(colnames(X) == colnames(X)[which(x == x)]) %in% c(3, 5, 7),
           2 * (1.1 * x / (x + 0.1) - 0.5),
           2 * (x - 0.5))
  })
  
  # Initialize Y
  Y <- rep(0, nrow(X))
  
  # First-order terms
  for (i in 1:10) {
    Y <- Y + 20 * w[,i]
  }
  
  # Second-order terms
  for (i in 1:5) {
    for (j in (i+1):6) {
      Y <- Y - 15 * w[,i] * w[,j]
    }
  }
  
  # Third-order terms
  for (i in 1:3) {
    for (j in (i+1):4) {
      for (l in (j+1):5) {
        Y <- Y - 10 * w[,i] * w[,j] * w[,l]
      }
    }
  }
  
  # Fourth-order terms
  Y <- Y + 5 * w[,1] * w[,2] * w[,3] * w[,4]
  
  return(Y)
}
```


```{r}
# Set up parameters
k <- 20  # number of parameters
nameParams <- paste("x", 1:k, sep = "")

# Generate input matrix
mat <- sobol_matrices(params = nameParams, N = N, type = "R", order = "third")

# Calculate output
Y <- morris_function(mat)

# Plot the histogram
ggplot(data.frame(Y), aes(x = Y)) +
  geom_histogram(bins = 30, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(title = "Output Distribution of Morris Function (UA)",
       x = "Y",
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10))
```

Sensitivity Analysis:
```{r}
# Perform Sobol sensitivity analysis up to the highest order possible
ind <- sobol_indices(Y = Y, N = N, params = nameParams)

# Plot the results
plot(ind) + 
  labs(title = "Sensitivity Analysis of Morris Function") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 12),
        axis.text = element_text(size = 10))
```


